{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55393\n"
     ]
    }
   ],
   "source": [
    "import ujson\n",
    "file = open(\"id_URL.json\",\"r\")\n",
    "urls_json = ujson.load(file)\n",
    "print(len(urls_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_urls = len(urls_json)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the words freq file\n",
    "freq = open(\"wordURLandFreq.json\",\"r\")\n",
    "words_freq = ujson.load(freq)\n",
    "freq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.log(math.e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# compute words' tf_idf score\n",
    "file = open(\"wordURLtfidf_idf.json\",\"w\")\n",
    "for term, termfreq in words_freq.items():\n",
    "    df = len(termfreq)\n",
    "    for url_id, tf in termfreq.items():\n",
    "        words_freq[term][url_id] = [(1+(math.log10(int(tf)))*(math.log10(total_num_urls/df))),(math.log10(total_num_urls/df))]\n",
    "        \n",
    "ujson.dump(words_freq,file)\n",
    "print(\"done\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tfidf_file = open(\"wordURLtfidf.json\",\"r\")\n",
    "tfidf_content = ujson.load(tfidf_file)\n",
    "tfidf_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5f8e5217bc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mword_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mujson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermfreqset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mword_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "parent_dir = \"/Users/jay/Desktop/CS121/HW3/output5.11/M3/words_index2.0\"\n",
    "\n",
    "for term, termfreqset in tfidf_content.items():\n",
    "    if len(term)<=20:\n",
    "        child1_dir = os.path.join(parent_dir, str(term[0]))\n",
    "        try:\n",
    "            os.mkdir(child1_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        file_name = os.path.join(child1_dir, str(term)+\".json\")\n",
    "\n",
    "        word_json = open(file_name,\"w\")\n",
    "        ujson.dump(termfreqset,word_json)\n",
    "        word_json.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "#os.mkdir(\"words_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"/Users/jay/Desktop/CS121/HW3/output5.11/M3/words_index2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "freq = open(\"wordURLandFreq.json\",\"r\")\n",
    "words_freq = ujson.load(freq)\n",
    "freq.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_len = {}\n",
    "for term, termfreq in words_freq.items():\n",
    "    \n",
    "    for url_id, tf in termfreq.items():\n",
    "        if url_id in url_len:\n",
    "            url_len[url_id] += tf\n",
    "        else:\n",
    "            url_len[url_id] = tf\n",
    "outputfile = open(\"url_len.json\",\"w\")\n",
    "ujson.dump(url_len,outputfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
